{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# %load /Users/hwayment/ipynb_defaults.py\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%pylab inline\n",
    "import os, sys\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('paper')\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.extend(['/mnt/c/Users/abreha.b/OneDrive - Stanford/rotations/das/arnie', '/mnt/c/Users/abreha.b/OneDrive - Stanford/rotations/das/'])\n",
    "os.environ[\"ARNIEFILE\"] = '/mnt/c/Users/abreha.b/OneDrive - Stanford/rotations/das/arnie/run.arnie'\n",
    "\n",
    "from DegScore import assign_loop_type\n",
    "from assign_loop_type import write_loop_assignments\n",
    "\n",
    "sys.path.append('/mnt/c/Users/abreha.b/OneDrive - Stanford/rotations/das/DegScore')\n",
    "\n",
    "from DegScore import DegScore\n",
    "from arnie.sample_structures import sample_structures\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to reproduce DegScore from Kaggle datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble(sequence, n=1000):\n",
    "    structs = sample_structures(sequence, n_samples=n, package='eternafold')\n",
    "    structs = [list(write_loop_assignments(s)) for s in structs]\n",
    "    return np.array(structs)\n",
    "\n",
    "def encode_input(df, window_size=1, pad=10, seq=True, struct=True, ensemble_size=0):\n",
    "    '''Creat input/output for regression model for predicting structure probing data.\n",
    "    Inputs:\n",
    "    \n",
    "    dataframe (in EternaBench RDAT format)\n",
    "    window_size: size of window (in one direction). so window_size=1 is a total window size of 3\n",
    "    pad: number of nucleotides at start to not include\n",
    "    seq (bool): include sequence encoding\n",
    "    struct (bool): include bpRNA structure encoding\n",
    "    \n",
    "    Outputs:\n",
    "    Input array (n_samples x n_features): array of windowed input features\n",
    "    feature_names (list): feature names\n",
    "    \n",
    "    '''\n",
    "    MAX_LEN = 68\n",
    "    BASES = ['A','U','G','C']\n",
    "    STRUCTS = ['H','E','I','M','B','S']\n",
    "    \n",
    "    inpts = []\n",
    "    labels = []\n",
    "\n",
    "    feature_kernel=[]\n",
    "    if seq:\n",
    "        feature_kernel.extend(BASES)\n",
    "    if struct:\n",
    "        feature_kernel.extend(STRUCTS)\n",
    "\n",
    "    feature_names = ['%s_%d' % (k, val) for val in range(-1*window_size, window_size+1) for k in feature_kernel]\n",
    "    \n",
    "    for i, row in tqdm(df.iterrows(), desc='Encoding inputs', total=len(df)):\n",
    "        arr = np.zeros([MAX_LEN,len(feature_kernel)])\n",
    "        \n",
    "        if ensemble_size > 0: # stochastically sample ensemble\n",
    "            ensemble = get_ensemble(row['sequence'], n=ensemble_size)\n",
    "        else: # use MEA structure\n",
    "            ensemble = np.array([list(row['predicted_loop_type'])])\n",
    "\n",
    "        for index in range(pad,MAX_LEN):\n",
    "            ctr=0\n",
    "\n",
    "            #encode sequence\n",
    "            if seq:\n",
    "                for char in BASES:\n",
    "                    if row['sequence'][index]==char:\n",
    "                        arr[index,ctr]+=1\n",
    "                    ctr+=1\n",
    "\n",
    "            if struct:\n",
    "                loop_assignments = ''.join(ensemble[:,index])\n",
    "                for char in STRUCTS:\n",
    "                    prob = loop_assignments.count(char) / len(loop_assignments)\n",
    "                    arr[index,ctr]+=prob\n",
    "                    ctr+=1\n",
    "                    \n",
    "        # add zero padding to the side\n",
    "        padded_arr = np.vstack([np.zeros([window_size,len(feature_kernel)]),arr[pad:], np.zeros([window_size,len(feature_kernel)])])\n",
    "\n",
    "        for index in range(pad,MAX_LEN):\n",
    "            new_index = index+window_size-pad\n",
    "            tmp = padded_arr[new_index-window_size:new_index+window_size+1]\n",
    "            inpts.append(tmp.flatten())\n",
    "            labels.append('%s_%d' % (row['id'], index))\n",
    "            \n",
    "    return np.array(inpts), feature_names, labels\n",
    "\n",
    "def encode_output(df, data_type='reactivity', pad=10):\n",
    "    '''Creat input/output for regression model for predicting structure probing data.\n",
    "    Inputs:\n",
    "    \n",
    "    dataframe (in EternaBench RDAT format)\n",
    "    data_type: column name for degradation\n",
    "    window_size: size of window (in one direction). so window_size=1 is a total window size of 3\n",
    "    pad: number of nucleotides at start to not include\n",
    "    \n",
    "    Outputs:\n",
    "    output array (n_samples): array of reactivity values\n",
    "    \n",
    "    '''\n",
    "    MAX_LEN = 68\n",
    "    \n",
    "    outpts = []\n",
    "    labels = []\n",
    "    # output identity should be in form id_00073f8be_0\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        for index in range(pad,MAX_LEN):\n",
    "            outpts.append(row[data_type][index])\n",
    "            labels.append('%s_%d' % (row['id'], index))\n",
    "            \n",
    "    return outpts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_train = pd.read_json('train.json',lines=True)\n",
    "kaggle_train = kaggle_train.loc[kaggle_train['SN_filter']==1]\n",
    "\n",
    "#kaggle_test = pd.read_json('test.json',lines=True)\n",
    "kaggle_test = pd.read_csv('test_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Max. expected accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb8aaaecc1144e9a70db73bed1b9ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Encoding inputs', max=1589.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd1c8151dc845319265777095fc0847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Encoding inputs', max=2493.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mea_inputs_train, mea_feature_names, _ = encode_input(kaggle_train, window_size=12)\n",
    "mea_inputs_test, _, mea_test_labels = encode_input(kaggle_test, window_size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ensemble-averaged encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3593b8077a934f5b8da907793422120c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Encoding inputs', max=1589.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2684998005b64d20a23aed02eb1ef676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Encoding inputs', max=2493.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_size = 100\n",
    "ens_inputs_train, ens_feature_names, _ = encode_input(kaggle_train, window_size=12, ensemble_size=ensemble_size)\n",
    "ens_inputs_test, _, ens_test_labels = encode_input(kaggle_test, window_size=12, ensemble_size=ensemble_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### MEA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting reactivity ...\n",
      "Fitting deg_Mg_pH10 ...\n",
      "Fitting deg_pH10 ...\n",
      "Fitting deg_Mg_50C ...\n",
      "Fitting deg_50C ...\n"
     ]
    }
   ],
   "source": [
    "mea_models = {}\n",
    "\n",
    "for output_type in ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C','deg_50C']:\n",
    "    mea_outputs_train, mea_outputs_labels = encode_output(kaggle_train, data_type=output_type)\n",
    "\n",
    "    # Clip negative values to 0\n",
    "    mea_outputs_train = np.clip(mea_outputs_train, 0, 100)\n",
    "\n",
    "    reg = Ridge(alpha=0.15)\n",
    "    print('Fitting %s ...' % output_type)\n",
    "    reg.fit(mea_inputs_train, mea_outputs_train)\n",
    "    \n",
    "    mea_models[output_type] = reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ensemble-averaged models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting reactivity ...\n",
      "Fitting deg_Mg_pH10 ...\n",
      "Fitting deg_pH10 ...\n",
      "Fitting deg_Mg_50C ...\n",
      "Fitting deg_50C ...\n"
     ]
    }
   ],
   "source": [
    "ens_models = {}\n",
    "\n",
    "for output_type in ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C','deg_50C']:\n",
    "    ens_outputs_train, ens_outputs_labels = encode_output(kaggle_train, data_type=output_type)\n",
    "    \n",
    "    # Clip negative values to 0\n",
    "    ens_outputs_train = np.clip(ens_outputs_train, 0, 100)\n",
    "\n",
    "    reg = Ridge(alpha=0.15)\n",
    "    print('Fitting %s ...' % output_type)\n",
    "    reg.fit(ens_inputs_train, ens_outputs_train)\n",
    "    \n",
    "    ens_models[output_type] = reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the existing class that contains \"DegScore-2.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_mcrmse(models, test_df):\n",
    "    scored_data_types = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']\n",
    "\n",
    "    seq_scores = []\n",
    "    for i, row in test_df.iterrows():\n",
    "        scores = []\n",
    "        for data_type in scored_data_types:\n",
    "            model = models[data_type]\n",
    "            \n",
    "            coeffs = model.coef_\n",
    "            inter = model.intercept_\n",
    "            \n",
    "            mdl = DegScore.DegScore(row['sequence'], structure=row['structure'], coeffs=coeffs, intercept=inter)\n",
    "            \n",
    "            seq_scored = row['seq_scored']\n",
    "            pred = mdl.degscore_by_position[:seq_scored]\n",
    "            target = np.array(json.loads(row[data_type])[:seq_scored])\n",
    "            \n",
    "            scores.extend(np.square(pred - target))\n",
    "        \n",
    "        seq_scores.append(scores)\n",
    "        \n",
    "    return np.mean(seq_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24691545925204095"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_mcrmse(mea_models, kaggle_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23856658661289426"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_mcrmse(ens_models, kaggle_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
